# NanGePlus AI Agent ä»“åº“å­¦ä¹ ç¬”è®°

**å­¦ä¹ æ—¥æœŸ**: 2026-01-31
**ä½œè€…**: lutra ğŸ¦¦
**ä»“åº“åœ°å€**: https://github.com/NanGePlus

---

## ä¸€ã€æ ¸å¿ƒå­¦ä¹ å†…å®¹

### 1. LangGraphChatBot - LangGraph å®Œæ•´æ¼”è¿›æ¡ˆä¾‹

**é¡¹ç›®ç»“æ„**:
```
LangGraphChatBot/
â”œâ”€â”€ 01_ChatBot/          # åŸºç¡€èŠå¤©æœºå™¨äºº
â”œâ”€â”€ 02_ChatBot/          # çŸ­æœŸè®°å¿†
â”œâ”€â”€ 03_ChatBotWithPostgres/  # PostgreSQL æŒä¹…åŒ–
â”œâ”€â”€ 04_RagAgent/         # RAG + å·¥å…·è°ƒç”¨ + æ™ºèƒ½åˆ†è¯Š
â””â”€â”€ README.md            # è¯¦ç»†æ–‡æ¡£
```

**æ ¸å¿ƒæ¶æ„æ¼”è¿›**:
1. **Phase 1**: ç®€å•å¯¹è¯ â†’ Graph åŸºç¡€
2. **Phase 2**: çŸ­æœŸè®°å¿† â†’ Graph çº¿ç¨‹å†…æŒä¹…åŒ–
3. **Phase 3**: é•¿æœŸè®°å¿† â†’ è·¨çº¿ç¨‹æŒä¹…åŒ–
4. **Phase 4**: æ™ºèƒ½åˆ†è¯Š â†’ å·¥å…·è°ƒç”¨ + åŠ¨æ€è·¯ç”±
5. **Phase 5**: API æœåŠ¡ â†’ FastAPI + Gradio

**å…³é”®æŠ€æœ¯ç‚¹**:

```python
# 1. çŠ¶æ€å®šä¹‰ (TypedDict)
class MessagesState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    relevance_score: Annotated[Optional[str], "Relevance score"]
    rewrite_count: Annotated[int, "Rewrite count"]

# 2. å·¥å…·è·¯ç”±é…ç½®
class ToolConfig:
    def __init__(self, tools):
        self.tools = tools
        self.tool_names = {tool.name for tool in tools}
        self.tool_routing_config = self._build_routing_config(tools)
    
    def _build_routing_config(self, tools):
        # æ£€ç´¢ç±»å·¥å…· â†’ grade_documents
        # éæ£€ç´¢ç±»å·¥å…· â†’ generate
        routing_config = {}
        for tool in tools:
            if "retrieve" in tool.name.lower():
                routing_config[tool.name] = "grade_documents"
            else:
                routing_config[tool.name] = "generate"
        return routing_config

# 3. å¹¶è¡Œå·¥å…·è°ƒç”¨
class ParallelToolNode:
    def __init__(self, max_workers=5):
        self.max_workers = max_workers
    
    def execute(self, tool_calls):
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(tool.invoke, call) for call in tool_calls]
            results = [f.result() for f in as_completed(futures)]
        return results

# 4. è®°å¿†ç³»ç»Ÿ
def store_memory(question, config, store):
    namespace = ("memories", config["configurable"]["user_id"])
    if "è®°ä½" in question.content.lower():
        store.put(namespace, str(uuid.uuid4()), {"data": question.content})

# 5. æ•°æ®åº“è¿æ¥æ± ç®¡ç†
from psycopg_pool import ConnectionPool
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
def test_connection(pool):
    with pool.getconn() as conn:
        cursor.execute("SELECT 1")
```

**ä¸“ä¸šå®è·µ**:
- æ—¥å¿—ç³»ç»Ÿ: `ConcurrentRotatingFileHandler` + çº¿ç¨‹å®‰å…¨
- æ¨¡æ¿ç¼“å­˜: `threading.Lock` + `prompt_cache`
- é”™è¯¯é‡è¯•: `tenacity` åº“
- çŠ¶æ€ç›‘æ§: å®šæœŸæ£€æŸ¥è¿æ¥æ± çŠ¶æ€

---

### 2. CrewAITest - å¤š Agent åä½œæ¡†æ¶

**é¡¹ç›®ç»“æ„**:
```
CrewAITest/
â”œâ”€â”€ crewaitest/              # åŸºç¡€å¤š Agent
â”œâ”€â”€ crewAIWithResearcher/    # ç ”ç©¶å‘˜ Agent
â”œâ”€â”€ crewAIWithRag/           # RAG Agent
â”œâ”€â”€ crewAIWithCoding/        # ç¼–ç  Agent
â”œâ”€â”€ crewAIWithHumanFeedback/ # äººç±»åé¦ˆ
â”œâ”€â”€ crewAIWithPipelines/     # Pipeline æ¨¡å¼
â””â”€â”€ crewAIWithFlows/         # Flow æ¨¡å¼
```

**Agent ç±»å‹**:
1. **åŸºç¡€ Agent**: å•ä¸ª Agent å®Œæˆä»»åŠ¡
2. **åä½œ Agent**: å¤šä¸ª Agent åˆ†å·¥åˆä½œ
3. **ç ”ç©¶å‘˜ Agent**: è°ƒç”¨å·¥å…· + PDF ç”Ÿæˆ
4. **RAG Agent**: çŸ¥è¯†åº“æ£€ç´¢
5. **Human-in-the-Loop Agent**: äººç±»å¹²é¢„

**CrewAI æ ¸å¿ƒæ¦‚å¿µ**:
```python
# Agent å®šä¹‰
researcher = Agent(
    role="Researcher",
    goal="Find and analyze information",
    backstory="Expert researcher with 10 years experience",
    tools=[search_tool, file_tool],
    llm=llm
)

# Task å®šä¹‰
research_task = Task(
    description="Research AI trends",
    expected_output="Detailed report",
    agent=researcher
)

# Crew ç¼–æ’
crew = Crew(
    agents=[researcher, writer],
    tasks=[research_task, writing_task],
    process=Process.sequential  # æˆ– Process.hierarchical
)

# æ‰§è¡Œ
result = crew.kickoff()
```

---

### 3. GraphragTest - GraphRAG çŸ¥è¯†å›¾è°±

**æ ¸å¿ƒæ¦‚å¿µ**:
```
ç´¢å¼•æµç¨‹ (Indexing):
  Document â†’ TextUnit â†’ Entity â†’ Relationship â†’ CommunityReport
  
æ£€ç´¢æµç¨‹ (Query):
  Local Search: åŸºäºå®ä½“çš„æ¨ç†
  Global Search: å…¨å±€æœç´¢
  DRIFT Search: æ··åˆæœ¬åœ°ä¸å…¨å±€
```

**å…³é”®ç»„ä»¶**:
- å®ä½“æå– (Entity Extraction)
- å…³ç³»æ£€æµ‹ (Relationship Detection)
- ç¤¾åŒºæ£€æµ‹ (Community Detection)
- ç¤¾ç¾¤æ‘˜è¦ (Community Summary)

**å¤šæ¨¡å‹æ”¯æŒ**:
- OpenAI (GPT-4o-mini)
- é˜¿é‡Œé€šä¹‰åƒé—®
- æ™ºè°± ChatGLM
- è®¯é£æ˜Ÿç«
- Ollama æœ¬åœ°æ¨¡å‹

---

### 4. ReActAgentsTest - ReAct Agent ç³»åˆ—

**åŠŸèƒ½æ¼”è¿›**:
1. **MCP Server é›†æˆ**: é«˜å¾·åœ°å›¾ MCP
2. **Human-in-the-Loop**: äººå·¥å®¡æŸ¥å·¥å…·è°ƒç”¨
3. **è®°å¿†ç³»ç»Ÿ**: çŸ­æœŸ + é•¿æœŸè®°å¿†
4. **å¤šä¼šè¯ç®¡ç†**: å†å²ä¼šè¯æ¢å¤
5. **ä»»åŠ¡ç®¡ç†**: é«˜å¹¶å‘å¼‚æ­¥è°ƒç”¨

---

## äºŒã€ä»£ç é£æ ¼å­¦ä¹ 

### 1. å‘½åè§„èŒƒ
```python
# ç±»å: PascalCase
class MessagesState:
class ToolConfig:
class DocumentRelevanceScore:

# å‡½æ•°å: snake_case
def store_memory():
def create_chain():
def monitor_connection_pool():

# å¸¸é‡: UPPER_SNAKE_CASE
MAX_BYTES = 5 * 1024 * 1024
BACKUP_COUNT = 3
```

### 2. æ³¨é‡Šè§„èŒƒ
```python
# æ–‡ä»¶é¡¶éƒ¨ç‰ˆæƒå£°æ˜
# Author:@å—å“¥AGIç ”ä¹ ç¤¾

# å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²
def create_chain(llm_chat, template_file: str, structured_output=None):
    """åˆ›å»º LLM å¤„ç†é“¾ï¼ŒåŠ è½½æç¤ºæ¨¡æ¿å¹¶ç»‘å®šæ¨¡å‹ï¼Œä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è¯»å–æ–‡ä»¶ã€‚
    
    Args:
        llm_chat: è¯­è¨€æ¨¡å‹å®ä¾‹ã€‚
        template_file: æç¤ºæ¨¡æ¿æ–‡ä»¶è·¯å¾„ã€‚
        structured_output: å¯é€‰çš„ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹ã€‚
    
    Returns:
        Runnable: é…ç½®å¥½çš„å¤„ç†é“¾ã€‚
    
    Raises:
        FileNotFoundError: å¦‚æœæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨ã€‚
    """
```

### 3. æ—¥å¿—è§„èŒƒ
```python
import logging
from concurrent_log_handler import ConcurrentRotatingFileHandler

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
handler = ConcurrentRotatingFileHandler(
    Config.LOG_FILE,
    maxBytes=Config.MAX_BYTES,
    backupCount=Config.BACKUP_COUNT
)
handler.setFormatter(logging.Formatter(
    "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
))
logger.addHandler(handler)
```

### 4. é”™è¯¯å¤„ç†
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
def test_connection(pool):
    """å¸¦é‡è¯•çš„æ•°æ®åº“è¿æ¥æµ‹è¯•"""
    try:
        # æ“ä½œ
    except Exception as e:
        logger.error(f"Error: {e}")
        raise
```

---

## ä¸‰ã€é€»è¾‘æ€ç»´å­¦ä¹ 

### 1. æ¸è¿›å¼å¼€å‘
```
ç‰ˆæœ¬1: åŸºç¡€åŠŸèƒ½
  â†“ å¢é‡è¿­ä»£
ç‰ˆæœ¬2: æ·»åŠ è®°å¿†
  â†“ å¢é‡è¿­ä»£
ç‰ˆæœ¬3: æŒä¹…åŒ–
  â†“ å¢é‡è¿­ä»£
ç‰ˆæœ¬4: å·¥å…·è°ƒç”¨
  â†“ å¢é‡è¿­ä»£
ç‰ˆæœ¬5: API æœåŠ¡
```

**å­¦åˆ°çš„**: ä¸è¦ä¸€æ¬¡å†™å®Œæ‰€æœ‰åŠŸèƒ½ï¼Œè€Œæ˜¯æ¸è¿›å¼è¿­ä»£ã€‚

### 2. æ¨¡å—åŒ–è®¾è®¡
```
utils/
â”œâ”€â”€ llms.py          # LLM åˆå§‹åŒ–
â”œâ”€â”€ tools_config.py  # å·¥å…·é…ç½®
â””â”€â”€ config.py        # ç»Ÿä¸€é…ç½®

prompts/
â”œâ”€â”€ agent.txt
â”œâ”€â”€ rewrite.txt
â”œâ”€â”€ grade.txt
â””â”€â”€ generate.txt
```

**å­¦åˆ°çš„**: é…ç½®æ–‡ä»¶ä¸ä»£ç åˆ†ç¦»ï¼Œå·¥å…·ä¸é€»è¾‘åˆ†ç¦»ã€‚

### 3. çŠ¶æ€ç®¡ç†
```
çŠ¶æ€å®šä¹‰ â†’ çŠ¶æ€ä¼ é€’ â†’ çŠ¶æ€æ›´æ–° â†’ çŠ¶æ€æŒä¹…åŒ–
```

**å­¦åˆ°çš„**: æ˜ç¡®çŠ¶æ€çš„è¾¹ç•Œå’Œç”Ÿå‘½å‘¨æœŸã€‚

---

## å››ã€å¼€å‘æ³¨æ„äº‹é¡¹

### 1. æ•°æ®åº“è¿æ¥æ± 
```python
# é”™è¯¯ç¤ºä¾‹: æ²¡æœ‰è¿æ¥æ± 
conn = psycopg2.connect(uri)

# æ­£ç¡®ç¤ºä¾‹: ä½¿ç”¨è¿æ¥æ± 
from psycopg_pool import ConnectionPool
pool = ConnectionPool(conninfo, max_size=20)
```

### 2. å¹¶å‘å®‰å…¨
```python
# é”™è¯¯ç¤ºä¾‹: å¤šçº¿ç¨‹ä¸å®‰å…¨
cache = {}

# æ­£ç¡®ç¤ºä¾‹: çº¿ç¨‹é”
cache = {}
lock = threading.Lock()

with lock:
    if key not in cache:
        cache[key] = load()
    value = cache[key]
```

### 3. é”™è¯¯é‡è¯•
```python
# å¤–éƒ¨ API è°ƒç”¨éœ€è¦é‡è¯•
@retry(stop=stop_after_attempt(3), wait=wait_exponential())
def call_api():
    requests.post(url, json=data)
```

### 4. èµ„æºæ¸…ç†
```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with ThreadPoolExecutor(max_workers=5) as executor:
    results = list(executor.map(func, items))
# è‡ªåŠ¨æ¸…ç†çº¿ç¨‹
```

### 5. æ—¥å¿—è½®è½¬
```python
# é˜²æ­¢æ—¥å¿—æ–‡ä»¶è¿‡å¤§
handler = ConcurrentRotatingFileHandler(
    "app.log",
    maxBytes=5*1024*1024,  # 5MB
    backupCount=3
)
```

---

## äº”ã€ä»€ä¹ˆåŠŸèƒ½å€¼å¾—å¼€å‘

### 1. é«˜ä»·å€¼åŠŸèƒ½ (â­â­â­â­â­)

| åŠŸèƒ½ | ä»·å€¼ | éš¾åº¦ | åŸå›  |
|------|------|------|------|
| RAG çŸ¥è¯†åº“ | é«˜ | ä¸­ | ç§æœ‰çŸ¥è¯†ç®¡ç†éœ€æ±‚å¤§ |
| å¤š Agent åä½œ | é«˜ | é«˜ | å¤æ‚ä»»åŠ¡åˆ†è§£ |
| è®°å¿†ç³»ç»Ÿ | é«˜ | ä¸­ | å¯¹è¯è¿ç»­æ€§ |
| Human-in-the-Loop | é«˜ | ä¸­ | å…³é”®å†³ç­–äººå·¥ç¡®è®¤ |

### 2. ä¸­ç­‰ä»·å€¼åŠŸèƒ½ (â­â­â­â­)

| åŠŸèƒ½ | ä»·å€¼ | éš¾åº¦ | åŸå›  |
|------|------|------|------|
| å·¥å…·è°ƒç”¨æ‰©å±• | ä¸­ | ä½ | å¿«é€Ÿæ‰©å±•èƒ½åŠ› |
| API æœåŠ¡å°è£… | ä¸­ | ä½ | ä¾¿äºé›†æˆ |
| å¤šæ¨¡å‹æ”¯æŒ | ä¸­ | ä½ | æˆæœ¬ä¼˜åŒ– |
| ä¼šè¯ç®¡ç† | ä¸­ | ä¸­ | ç”¨æˆ·ä½“éªŒ |

### 3. åŸºç¡€åŠŸèƒ½ (â­â­â­)

| åŠŸèƒ½ | ä»·å€¼ | éš¾åº¦ | åŸå›  |
|------|------|------|------|
| åŸºç¡€å¯¹è¯ | ä½ | ä½ | ç«äº‰æ¿€çƒˆ |
| ç®€å•é—®ç­” | ä½ | ä½ | åŒè´¨åŒ–ä¸¥é‡ |
| å•è½®ä»»åŠ¡ | ä½ | ä½ | ç²˜æ€§ä½ |

---

## å…­ã€Agent æ¡†æ¶å¯¹æ¯”

### 1. LangGraph vs CrewAI

| ç»´åº¦ | LangGraph | CrewAI |
|------|-----------|--------|
| æ§åˆ¶ç²’åº¦ | ç»†ç²’åº¦ | ç²—ç²’åº¦ |
| å­¦ä¹ æ›²çº¿ | è¾ƒé™¡ | è¾ƒå¹³ç¼“ |
| çµæ´»æ€§ | é«˜ | ä¸­ |
| å¤š Agent | éœ€è‡ªè¡Œå®ç° | å†…ç½®æ”¯æŒ |
| é€‚ç”¨åœºæ™¯ | å¤æ‚å·¥ä½œæµ | ä»»åŠ¡åˆ†å·¥ |

**é€‰æ‹©å»ºè®®**:
- å¤æ‚æµç¨‹ + è‡ªå®šä¹‰ â†’ LangGraph
- å¿«é€Ÿå®ç° + å¤š Agent â†’ CrewAI

### 2. RAG æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| ä¼ ç»Ÿ RAG | ç®€å• | å…¨å±€ç†è§£å·® |
| GraphRAG | å…³ç³»ç†è§£å¼º | æ„å»ºæˆæœ¬é«˜ |
| HyDE | æ£€ç´¢å‡†ç¡® | å»¶è¿Ÿé«˜ |

---

## ä¸ƒã€å®è·µå»ºè®®

### 1. å­¦ä¹ è·¯å¾„
```
Week 1: LangChain åŸºç¡€
  â†’ Prompt Engineering
  â†’ LLM è°ƒç”¨å°è£…
  
Week 2: LangGraph å…¥é—¨
  â†’ çŠ¶æ€ç®¡ç†
  â†’ èŠ‚ç‚¹ä¸è¾¹
  
Week 3: å·¥å…·ä¸è®°å¿†
  â†’ å·¥å…·è°ƒç”¨
  â†’ è®°å¿†ç³»ç»Ÿ
  
Week 4: å¤š Agent
  â†’ CrewAI
  â†’ Multi-Agent åä½œ
```

### 2. é¡¹ç›®æ¨è

**åˆçº§é¡¹ç›®** (1-2å‘¨):
- æ™ºèƒ½å®¢æœåŸºç¡€ç‰ˆ
- RAG çŸ¥è¯†åº“é—®ç­”

**ä¸­çº§é¡¹ç›®** (2-4å‘¨):
- å¸¦è®°å¿†çš„å¯¹è¯æœºå™¨äºº
- å·¥å…·è°ƒç”¨ Agent

**é«˜çº§é¡¹ç›®** (1-2æœˆ):
- å¤š Agent åä½œç³»ç»Ÿ
- ç”Ÿäº§çº§ Agent æœåŠ¡

### 3. é¿å‘æŒ‡å—

1. **ä¸è¦è¿‡åº¦è®¾è®¡**: ä»ç®€å•å¼€å§‹ï¼Œæ¸è¿›å¼è¿­ä»£
2. **ä¸è¦å¿½è§†æµ‹è¯•**: å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•
3. **ä¸è¦å¿½ç•¥ç›‘æ§**: æ—¥å¿— + æŒ‡æ ‡ + å‘Šè­¦
4. **ä¸è¦ç¡¬ç¼–ç **: é…ç½®å¤–ç½® + ç¯å¢ƒå˜é‡

---

## å…«ã€æ ¸å¿ƒä»£ç æ¨¡æ¿

### 1. LangGraph Agent æ¨¡æ¿

```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, Annotated
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    context: dict

def agent_node(state, config):
    """Agent å†³ç­–èŠ‚ç‚¹"""
    # å†³ç­–é€»è¾‘
    return {"messages": [response]}

def tool_node(state):
    """å·¥å…·è°ƒç”¨èŠ‚ç‚¹"""
    # å·¥å…·æ‰§è¡Œ
    return {"messages": [tool_result]}

def router(state):
    """è·¯ç”±å†³ç­–"""
    if need_tools:
        return "tool_node"
    return END

# æ„å»ºå›¾
graph = StateGraph(AgentState)
graph.add_node("agent", agent_node)
graph.add_node("tools", tool_node)
graph.add_edge(START, "agent")
graph.add_conditional_edges("agent", router)
graph.add_edge("tools", "agent")

# æŒä¹…åŒ–
from langgraph.checkpoint.memory import MemorySaver
checkpointer = MemorySaver()
app = graph.compile(checkpointer=checkpointer)
```

### 2. å¤š Agent åä½œæ¨¡æ¿

```python
from crewai import Agent, Task, Crew, Process

# å®šä¹‰ Agent
researcher = Agent(
    role="Researcher",
    goal="Research topics thoroughly",
    backstory="Expert researcher",
    tools=[search_tool]
)

writer = Agent(
    role="Writer",
    goal="Write clear reports",
    backstory="Professional writer"
)

# å®šä¹‰ Task
research = Task(
    description="Research AI trends",
    expected_output="Detailed report",
    agent=researcher
)

write = Task(
    description="Write summary",
    expected_output="Summary document",
    agent=writer
)

# ç¼–æ’ Crew
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    process=Process.sequential
)

result = crew.kickoff()
```

### 3. RAG æ¨¡æ¿

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# æ–‡æ¡£å¤„ç†
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

# å‘é‡åŒ–
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documents, embeddings)

# æ£€ç´¢
retriever = vectorstore.as_retriever()

# ç”Ÿæˆ
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4")

from langchain.chains import RetrievalQA
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff"
)
```

---

## ä¹ã€æ€»ç»“

### æ ¸å¿ƒæ”¶è·

1. **æ¶æ„æ€ç»´**: æ¸è¿›å¼å¼€å‘ã€æ¨¡å—åŒ–è®¾è®¡ã€çŠ¶æ€ç®¡ç†
2. **å·¥ç¨‹å®è·µ**: è¿æ¥æ± ã€æ—¥å¿—ã€é”™è¯¯é‡è¯•ã€å¹¶å‘å®‰å…¨
3. **Agent è®¤çŸ¥**: ReAct æ¨¡å¼ã€å·¥å…·è°ƒç”¨ã€è®°å¿†ç³»ç»Ÿã€å¤š Agent åä½œ
4. **æŠ€æœ¯é€‰å‹**: LangGraph vs CrewAI, ä¼ ç»Ÿ RAG vs GraphRAG

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… å­¦ä¹ å®Œæˆ: NanGePlus ä»“åº“åˆ†æ
2. â¬œ å®è·µé¡¹ç›®: åŸºäº LangGraph çš„ç§‘ç ”åŠ©æ‰‹ Agent
3. â¬œ å·¥å…·å¼€å‘: å¤šæ¨¡å‹æ”¯æŒå°è£…
4. â¬œ çŸ¥è¯†è¾“å‡º: æ•´ç†æ•™ç¨‹å†…å®¹

---

*ç¬”è®°ç”Ÿæˆæ—¶é—´: 2026-01-31*
*æ¥æº: https://github.com/NanGePlus*
