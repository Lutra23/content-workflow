#!/usr/bin/env python3
"""
Content Factory - Production-grade Content Workflow System

Features:
- Topic discovery via Tavily API + GitHub API
- Multi-AI provider support (Yunwu, OpenRouter, Groq, DeepSeek, Silicon)
- Content generation with templates
- Multi-platform publishing workflow
- Cron-ready automation

API Providers (æŒ‰æ€§ä»·æ¯”æ’åº):
1. Groq - æœ€å¿«æœ€ä¾¿å®œ ($0.0003/1k)
2. DeepSeek - ä¾¿å®œ ($0.00014/1k)
3. SiliconFlow - ä¾¿å®œ ($0.0001/1k)
4. OpenRouter - å¤šæ¨¡å‹ ($0.003/1k Claude)
5. Yunwu - Claude å›½å†… ($0.003/1k)
"""

import os
import sys
import json
import yaml
import time
import hashlib
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
import requests

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/workflow.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class Platform(Enum):
    """Publishing platforms"""
    ZHIHU = "zhihu"
    BILIBILI = "bilibili"
    XIAOHONGSHU = "xiaohongshu"
    GITHUB = "github"
    BLOG = "blog"
    NOTION = "notion"


class ContentStatus(Enum):
    """Content status"""
    DRAFT = "draft"
    REVIEW = "review"
    SCHEDULED = "scheduled"
    PUBLISHED = "published"
    ARCHIVED = "archived"


@dataclass
class Topic:
    """Discovered topic"""
    id: str
    title: str
    description: str
    keywords: List[str]
    source: str
    url: str
    engagement: int
    discovered_at: str
    used: bool = False
    
    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class Content:
    """Content item"""
    id: str
    topic_id: str
    platform: Platform
    title: str
    body: str
    outline: str
    seo_description: str
    tags: List[str]
    status: ContentStatus
    created_at: str
    updated_at: str
    published_at: Optional[str] = None
    views: int = 0
    likes: int = 0
    comments: int = 0
    
    def to_dict(self) -> Dict:
        data = asdict(self)
        data['platform'] = self.platform.value
        data['status'] = self.status.value
        return data


class TavilyClient:
    """Tavily API client for topic research"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.tavily.com"
    
    def search(self, query: str, topic: str = "general",
               days: int = 7, max_results: int = 10,
               include_raw_content: bool = False) -> List[Dict]:
        """Search for topics"""
        try:
            response = requests.post(
                f"{self.base_url}/search",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "query": query,
                    "topic": topic,
                    "days": days,
                    "max_results": max_results,
                    "include_answer": True,
                    "include_raw_content": include_raw_content,
                },
                timeout=30
            )
            response.raise_for_status()
            return response.json().get("results", [])
        except Exception as e:
            logger.error(f"Tavily search error: {e}")
            return []
    
    def get_answer(self, query: str) -> str:
        """Get direct answer"""
        try:
            response = requests.post(
                f"{self.base_url}/answer",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={"query": query},
                timeout=30
            )
            response.raise_for_status()
            return response.json().get("answer", "")
        except Exception as e:
            logger.error(f"Tavily answer error: {e}")
            return ""


class GitHubClient:
    """GitHub API client for trending topics"""
    
    def __init__(self):
        self.base_url = "https://api.github.com"
        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "ContentFactory/1.0"
        }
    
    def get_trending(self, language: str = "python", 
                     since: str = "daily") -> List[Dict]:
        """Get trending repositories"""
        try:
            query = f"language:{language} stars:>1000"
            if since == "daily":
                yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
                query += f" created:>{yesterday}"
            
            response = requests.get(
                f"{self.base_url}/search/repositories",
                headers=self.headers,
                params={"q": query, "sort": "stars", "order": "desc", "per_page": 10},
                timeout=30
            )
            response.raise_for_status()
            items = response.json().get("items", [])
            
            return [{
                "title": f"{r['owner']['login']}/{r['name']}",
                "description": r.get("description", ""),
                "stars": r["stargazers_count"],
                "url": r["html_url"],
                "language": r.get("language", ""),
            } for r in items]
        except Exception as e:
            logger.error(f"GitHub API error: {e}")
            return []


class AIClient:
    """
    Multi-AI provider client
    
    Priority (æ€§ä»·æ¯”):
    1. Groq - æœ€å¿«æœ€ä¾¿å®œ ($0.0003/1k tokens)
    2. DeepSeek - ä¾¿å®œ ($0.00014/1k tokens)
    3. SiliconFlow - ä¾¿å®œ ($0.0001/1k tokens)
    4. OpenRouter - Claude ($0.003/1k tokens)
    5. Yunwu - Claude å›½å†… ($0.003/1k tokens)
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.primary_provider = config.get("provider", "groq")
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºçš„æä¾›å•†
        self.provider_order = config.get(
            "providers", 
            ["groq", "deepseek", "silicon", "openrouter", "yunwu"]
        )
    
    def generate(self, prompt: str, max_tokens: int = 2000) -> str:
        """Try providers in order until one works"""
        errors = {}
        
        for provider in self.provider_order:
            try:
                method = getattr(self, f"_generate_{provider}", None)
                if method:
                    result = method(prompt, max_tokens)
                    if result and not result.startswith("[AIç”Ÿæˆå†…å®¹]"):
                        return result
                    errors[provider] = "empty/placeholder"
                else:
                    errors[provider] = "no method"
            except Exception as e:
                errors[provider] = str(e)[:30]
        
        # Hard-fail so callers don't accidentally persist a fake/placeholder draft.
        logger.error(f"All providers failed: {errors}")
        raise RuntimeError(f"All AI providers failed: {errors}")
    
    def _generate_groq(self, prompt: str, max_tokens: int) -> str:
        """Groq - æœ€å¿«æœ€ä¾¿å®œ"""
        api_key = os.environ.get("GROQ_API_KEY", "").strip()
        if not api_key:
            raise RuntimeError("Missing GROQ_API_KEY environment variable")
        
        model = self.config.get("model", "llama-3.3-70b-versatile")
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.7,
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    
    def _generate_deepseek(self, prompt: str, max_tokens: int) -> str:
        """DeepSeek - ä¾¿å®œ"""
        api_key = os.environ.get("DEEPSEEK_API_KEY", "").strip()
        if not api_key:
            raise RuntimeError("Missing DEEPSEEK_API_KEY environment variable")
        
        response = requests.post(
            "https://api.deepseek.com/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.7,
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    
    def _generate_silicon(self, prompt: str, max_tokens: int) -> str:
        """SiliconFlow - ä¾¿å®œ"""
        # Support both names; many environments use SILICONFLOW_API_KEY.
        api_key = (os.environ.get("SILICON_API_KEY", "").strip()
                  or os.environ.get("SILICONFLOW_API_KEY", "").strip())
        if not api_key:
            raise RuntimeError("Missing SILICON_API_KEY (or SILICONFLOW_API_KEY) environment variable")
        
        # SiliconFlow model ids differ from DeepSeek/OpenAI-style names.
        # Use a sane default that exists in /v1/models.
        model = (
            self.config.get("silicon_model")
            or self.config.get("siliconflow_model")
            or self.config.get("model")
            or "deepseek-ai/DeepSeek-V3"
        )
        
        response = requests.post(
            "https://api.siliconflow.cn/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.7,
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    
    def _generate_openrouter(self, prompt: str, max_tokens: int) -> str:
        """OpenRouter - å¤šæ¨¡å‹"""
        api_key = os.environ.get("OPENROUTER_API_KEY", "").strip()
        if not api_key:
            raise RuntimeError("Missing OPENROUTER_API_KEY environment variable")
        
        model = self.config.get("model", "anthropic/claude-sonnet-4-20250514")
        
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "HTTP-Referer": "https://content-factory.dev",
            },
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.7,
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    
    def _generate_yunwu(self, prompt: str, max_tokens: int) -> str:
        """Yunwu - Claude å›½å†…"""
        api_key = os.environ.get("YUNWU_API_KEY", "").strip()
        if not api_key:
            raise RuntimeError("Missing YUNWU_API_KEY environment variable")
        
        model = self.config.get("model", "claude-3-5-sonnet")
        
        response = requests.post(
            "https://yunwu.ai/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.7,
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    
    def generate_article(self, topic: Topic, style: str = "professional", research: str = "") -> Dict:
        """Generate full article"""
        prompt = f"""
ä½ æ˜¯ä¸­æ–‡å†…å®¹å†™ä½œä¸“å®¶ï¼Œæ“…é•¿æŠŠæŠ€æœ¯/å·¥å…·ç±»ä¿¡æ¯å†™æˆèƒ½å‘å¸ƒçš„å…¬ä¼—å·é•¿æ–‡ã€‚

ã€ç¡¬æ€§è¦æ±‚ã€‘
- è¾“å‡ºè¯­è¨€ï¼šç®€ä½“ä¸­æ–‡
- ç›´æ¥è¾“å‡º Markdown æ­£æ–‡ï¼ˆä¸è¦åŒ… ```markdown ä»£ç å—ï¼‰
- ä¸è¦å‡ºç°â€œä½œä¸ºAI/æˆ‘æ— æ³•/å…è´£å£°æ˜/å‚è€ƒèµ„æ–™â€ç­‰åºŸè¯
- å†…å®¹å¿…é¡»å…·ä½“ã€å¯æ‰§è¡Œï¼Œé¿å…ç©ºæ³›
- **é»˜è®¤ç¦æ­¢å‡ºç°ä»»ä½•å…·ä½“æ•°å­—ï¼ˆç™¾åˆ†æ¯”/å€æ•°/é‡‘é¢/æ—¶é—´/æ’åç­‰ï¼‰**ã€‚
  - åªæœ‰å½“ã€å¯ç”¨èµ„æ–™ã€‘çš„æ‘˜è¦é‡Œæ˜ç¡®å‡ºç°äº†è¯¥æ•°å­—ï¼Œä½ æ‰å¯ä»¥ä½¿ç”¨ï¼Œå¹¶åœ¨å¥æœ«ç”¨æ‹¬å·æ ‡æ³¨å¯¹åº”æ¥æºé“¾æ¥ï¼ˆURLï¼‰ã€‚
  - å¦‚æœèµ„æ–™é‡Œæ²¡å†™ï¼Œå°±æŠŠè¡¨è¾¾æ”¹æˆä¸å«æ•°å­—çš„ç»éªŒåˆ¤æ–­ï¼ˆä¾‹å¦‚â€œæ˜æ˜¾â€â€œå¤šæ•°â€â€œå°‘æ•°â€â€œå¤§å¹…â€ï¼‰ã€‚

ã€æ–‡ç« ä¿¡æ¯ã€‘
ä¸»é¢˜ï¼š{topic.title}
è¡¥å……æè¿°ï¼š{topic.description}
å…³é”®è¯ï¼š{", ".join(topic.keywords)}
é£æ ¼ï¼š{style}

ã€å¯ç”¨èµ„æ–™ï¼ˆå¿…é¡»ä½¿ç”¨ï¼Œç¦æ­¢å‡­ç©ºç¼–é€ äº‹å®/æ•°æ®ï¼‰ã€‘
{research}

ã€ç»“æ„è¦æ±‚ã€‘
1) æ ‡é¢˜ï¼š1 è¡Œï¼ˆ# å¼€å¤´ï¼‰
2) å¼€å¤´ï¼š3~6 å¥å¼º hookï¼ˆç—›ç‚¹ + ç»“æœ + åå¸¸è¯†ï¼‰
3) æ­£æ–‡ï¼šè‡³å°‘ 5 ä¸ªäºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰ï¼Œæ¯èŠ‚ç»™å‡ºè¦ç‚¹/æ­¥éª¤/ä¾‹å­ï¼›æ¯èŠ‚è‡³å°‘å¼•ç”¨ 1 ä¸ªæ¥æºé“¾æ¥ï¼ˆç”¨æ‹¬å·æ”¾ URLï¼‰ã€‚
   - å¼•ç”¨çš„ç›®çš„æ˜¯â€œå‘Šè¯‰è¯»è€…ä½ æ˜¯ä»å“ªå„¿æ¥çš„â€ï¼Œä¸æ˜¯ç»™èƒ¡ç¼–æ•°æ®è´´ä¸ªé“¾æ¥ã€‚
4) ç»“å°¾ï¼šç»™ä¸€ä¸ª 7 å¤©è¡ŒåŠ¨æ¸…å•ï¼ˆå¯æ‰“å‹¾çš„ checklistï¼‰â€”â€”å¿…é¡»å®Œæ•´ 7 æ¡ï¼Œä¸”æ¯æ¡éƒ½è¦å…·ä½“å¯æ‰§è¡Œï¼Œç¦æ­¢ç•™ç©º
5) æ€»å­—æ•°ï¼š1200~1800 å­—

ç°åœ¨å¼€å§‹å†™ã€‚
"""
        content = self.generate(prompt, max_tokens=3000)
        
        # Parse outline
        lines = content.split('\n')
        outline_lines = [l for l in lines if l.startswith('##')]
        outline = '\n'.join(outline_lines)
        
        return {
            "title": topic.title if len(topic.title) < 60 else topic.title[:57] + "...",
            "body": content,
            "outline": outline,
            "seo_description": topic.description[:150],
            "tags": topic.keywords[:5],
        }
    
    def generate_video_script(self, topic: Topic) -> Dict:
        """Generate video script"""
        prompt = f"""
ä½ æ˜¯ä¸­æ–‡è§†é¢‘ç¼–å¯¼ï¼Œç»™ B ç«™åšæŠ€æœ¯ç±»å£æ’­è„šæœ¬ã€‚

ã€ç¡¬æ€§è¦æ±‚ã€‘
- è¾“å‡ºè¯­è¨€ï¼šç®€ä½“ä¸­æ–‡
- ä¸è¦å‡ºç°â€œä½œä¸ºAI/æˆ‘æ— æ³•/å…è´£å£°æ˜â€
- å£è¯­åŒ–ã€èŠ‚å¥å¿«ã€èƒ½ç›´æ¥å¿µ

ã€è§†é¢‘ä¿¡æ¯ã€‘
ä¸»é¢˜ï¼š{topic.title}
è¡¥å……æè¿°ï¼š{topic.description}

ã€ç»“æ„ã€‘
[å¼€åœºç™½ 10ç§’]
[ä¸ºä»€ä¹ˆå€¼å¾—çœ‹ 20ç§’]
[æ­£æ–‡è¦ç‚¹ x4]ï¼ˆæ¯ç‚¹ç»™ä¾‹å­/ç±»æ¯”ï¼‰
[æ€»ç»“]
[äº’åŠ¨å¼•å¯¼]

æ€»æ—¶é•¿ï¼š3-5 åˆ†é’Ÿã€‚

ç°åœ¨å¼€å§‹å†™ï¼š
"""
        content = self.generate(prompt, max_tokens=2000)
        
        return {
            "title": f"ã€AIå®æˆ˜ã€‘{topic.title}",
            "body": content,
            "outline": "å¼€åœºç™½ â†’ è¦ç‚¹1 â†’ è¦ç‚¹2 â†’ è¦ç‚¹3 â†’ ç»“å°¾",
            "seo_description": f"åˆ†äº«å…³äº{topic.title}çš„å®æˆ˜ç»éªŒ",
            "tags": ["AI", "æŠ€æœ¯åˆ†äº«"] + topic.keywords[:3],
        }


class ContentFactory:
    """Main content workflow system"""
    
    def __init__(self, config_file: str = "config.yaml"):
        self.config = self._load_config(config_file)
        self.data_dir = Path(self.config.get("data_dir", "./data"))
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize clients
        self._init_clients()
        
        # Data files
        self.topics_file = self.data_dir / "topics.json"
        self.content_file = self.data_dir / "content.json"
        
        # Initialize files
        if not self.topics_file.exists():
            self.topics_file.write_text("[]")
        if not self.content_file.exists():
            self.content_file.write_text("[]")
        
        logger.info("ğŸš€ ContentFactory initialized")
    
    def _load_config(self, config_file: str) -> Dict:
        """Load configuration"""
        default = {
            "data_dir": "./data",
            "tavily_api_key": os.environ.get("TAVILY_API_KEY", ""),
            # Default to SiliconFlow since this workspace typically has SILICONFLOW_API_KEY configured.
            "ai_provider": "silicon",
            "providers": ["silicon", "deepseek", "groq", "openrouter", "yunwu"],
            # Language control for prompts.
            "output_language": "zh-CN",
            # SiliconFlow model override (must exist in https://api.siliconflow.cn/v1/models)
            "silicon_model": "Pro/moonshotai/Kimi-K2.5",
        }
        
        if Path(config_file).exists():
            with open(config_file) as f:
                user = yaml.safe_load(f)
                default.update(user)
        
        return default
    
    def _init_clients(self):
        """Initialize API clients"""
        # Tavily
        tavily_key = self.config.get("tavily_api_key", "")
        if tavily_key:
            self.tavily = TavilyClient(tavily_key)
            logger.info("âœ… Tavily client ready")
        else:
            self.tavily = None
            logger.info("â„¹ï¸  Tavily not configured (using GitHub only)")
        
        # GitHub
        self.github = GitHubClient()
        logger.info("âœ… GitHub client ready")
        
        # AI
        ai_config = {
            "provider": self.config.get("ai_provider", "groq"),
            "providers": self.config.get("providers", ["groq", "deepseek", "silicon"]),
        }
        self.ai = AIClient(ai_config)
        logger.info(f"âœ… AI client ready ({ai_config['providers'][0]})")
    
    def _gen_id(self, prefix: str) -> str:
        """Generate unique ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{prefix}_{timestamp}"
    
    def discover_topics(self, limit: int = 10) -> List[Topic]:
        """Discover trending topics"""
        topics = []
        
        # GitHub trending
        logger.info("ğŸ“Š Fetching GitHub trending...")
        repos = self.github.get_trending("python", "weekly")
        for r in repos[:5]:
            topic = Topic(
                id=self._gen_id("gh"),
                title=r["title"],
                description=r["description"][:200] if r["description"] else "",
                keywords=[r["language"], "GitHub", "trending"],
                source="github",
                url=r["url"],
                engagement=r["stars"],
                discovered_at=datetime.now().isoformat(),
            )
            topics.append(topic)
        
        # Tavily search
        if self.tavily:
            logger.info("ğŸ” Searching Tavily...")
            queries = [
                "AI automation tools 2026",
                "ChatGPT workflow examples",
                "productivity system automation",
            ]
            for q in queries[:2]:
                results = self.tavily.search(q, max_results=3)
                for i, r in enumerate(results):
                    topic = Topic(
                        id=self._gen_id("tv"),
                        title=r.get("title", q),
                        description=r.get("content", "")[:200],
                        keywords=q.split(),
                        source="tavily",
                        url=r.get("url", ""),
                        engagement=i * 10,
                        discovered_at=datetime.now().isoformat(),
                    )
                    topics.append(topic)
        
        # Save topics
        existing = json.loads(self.topics_file.read_text()) if self.topics_file.exists() else []
        existing.extend([t.to_dict() for t in topics])
        self.topics_file.write_text(json.dumps(existing, indent=2, ensure_ascii=False))
        
        logger.info(f"âœ… Discovered {len(topics)} topics")
        return topics
    
    def get_unused_topics(self, limit: int = 5) -> List[Topic]:
        """Get unused topics"""
        all_topics = json.loads(self.topics_file.read_text()) if self.topics_file.exists() else []
        unused = [Topic(**t) for t in all_topics if not t.get("used", False)]
        return unused[:limit]
    
    def mark_topic_used(self, topic_id: str):
        """Mark topic as used"""
        topics = json.loads(self.topics_file.read_text())
        for t in topics:
            if t["id"] == topic_id:
                t["used"] = True
        self.topics_file.write_text(json.dumps(topics, indent=2, ensure_ascii=False))

    def build_research_packet(self, topic: Topic, max_sources: int = 5) -> str:
        """Build a compact research packet (bullets + URLs) for grounded writing."""
        lines: List[str] = []

        # Always include the original topic URL (if any)
        if topic.url:
            lines.append(f"- åŸå§‹é“¾æ¥ï¼š{topic.url}")

        if not getattr(self, "tavily", None):
            lines.append("- ï¼ˆTavily æœªé…ç½®ï¼šè¯·ä»…åŸºäºå¸¸è¯†å†™ä½œï¼Œé¿å…ä»»ä½•å…·ä½“æ•°å­—/æ–­è¨€ï¼‰")
            return "\n".join(lines)

        # Use Tavily search to gather supporting sources
        results = self.tavily.search(
            query=topic.title,
            topic="general",
            days=30,
            max_results=max_sources,
            include_raw_content=False,
        )

        for r in results[:max_sources]:
            title = (r.get("title") or "").strip()
            url = (r.get("url") or "").strip()
            snippet = (r.get("content") or r.get("answer") or "").strip()
            snippet = " ".join(snippet.split())
            if snippet:
                snippet = snippet[:280]
            if url:
                if title:
                    lines.append(f"- {title}ï¼ˆ{url}ï¼‰")
                else:
                    lines.append(f"- {url}")
            if snippet:
                lines.append(f"  - æ‘˜è¦ï¼š{snippet}")

        # Hard constraint reminder
        lines.append("- å†™ä½œè§„åˆ™ï¼šä»»ä½•å…·ä½“æ•°å­—/ç»Ÿè®¡/æ³•è§„/åŠŸèƒ½æ–­è¨€éƒ½å¿…é¡»å¼•ç”¨ä»¥ä¸Šé“¾æ¥ï¼Œå¦åˆ™åˆ æ‰æ•°å­—ã€‚")
        return "\n".join(lines)

    def generate_content(self, topic: Topic, content_type: str = "article") -> Optional[Content]:
        """Generate content from topic"""
        logger.info(f"ğŸ“ Generating {content_type} for: {topic.title}")
        
        try:
            if content_type == "article":
                research = self.build_research_packet(topic)
                result = self.ai.generate_article(topic, research=research)
            else:
                result = self.ai.generate_video_script(topic)
            
            content = Content(
                id=self._gen_id("c"),
                topic_id=topic.id,
                platform=Platform.ZHIHU,
                title=result["title"],
                body=result["body"],
                outline=result["outline"],
                seo_description=result["seo_description"],
                tags=result["tags"],
                status=ContentStatus.DRAFT,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
            )
            
            # Save content
            existing = json.loads(self.content_file.read_text()) if self.content_file.exists() else []
            existing.append(content.to_dict())
            self.content_file.write_text(json.dumps(existing, indent=2, ensure_ascii=False))
            
            self.mark_topic_used(topic.id)
            logger.info(f"âœ… Generated: {content.id}")
            return content
            
        except Exception as e:
            logger.error(f"Generation error: {e}")
            return None
    
    def get_draft_content(self) -> List[Content]:
        """Get all draft content"""
        if not self.content_file.exists():
            return []
        items = json.loads(self.content_file.read_text())
        return [Content(**c) for c in items if c["status"] == "draft"]
    
    def get_status(self) -> Dict:
        """Get workflow status"""
        topics = json.loads(self.topics_file.read_text()) if self.topics_file.exists() else []
        content = json.loads(self.content_file.read_text()) if self.content_file.exists() else []
        
        return {
            "total_topics": len(topics),
            "unused_topics": len([t for t in topics if not t.get("used", False)]),
            "draft_content": len([c for c in content if c["status"] == "draft"]),
            "published_content": len([c for c in content if c["status"] == "published"]),
        }
    
    def run_daily(self):
        """Run complete daily workflow"""
        logger.info("ğŸš€ Starting daily content workflow...")
        
        # 1. Discover topics
        topics = self.discover_topics()
        
        # 2. Get unused topics
        unused = self.get_unused_topics(3)
        
        # 3. Generate content for top topic
        if unused:
            top_topic = unused[0]
            content = self.generate_content(top_topic, "article")
            
            if content:
                logger.info(f"ğŸ“„ Generated: {content.title}")
        
        # 4. Summary
        status = self.get_status()
        logger.info(f"\nğŸ“Š Daily Summary:")
        logger.info(f"   Topics: {status['total_topics']} ({status['unused_topics']} unused)")
        logger.info(f"   Drafts: {status['draft_content']}")
        logger.info(f"   Published: {status['published_content']}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Content Factory")
    subparsers = parser.add_subparsers(dest="command")
    
    subparsers.add_parser("daily", help="Run daily workflow")
    subparsers.add_parser("status", help="Show status")
    subparsers.add_parser("discover", help="Discover topics")
    
    gen_parser = subparsers.add_parser("generate", help="Generate content")
    gen_parser.add_argument("topic_id", help="Topic ID")
    gen_parser.add_argument("--type", "-t", default="article", choices=["article", "video"])
    
    args = parser.parse_args()
    
    factory = ContentFactory()
    
    if args.command == "daily":
        factory.run_daily()
    elif args.command == "status":
        s = factory.get_status()
        for k, v in s.items():
            print(f"  {k}: {v}")
    elif args.command == "discover":
        factory.discover_topics()
    elif args.command == "generate":
        topics = factory.get_unused_topics()
        topic = next((t for t in topics if t.id == args.topic_id), None)
        if topic:
            factory.generate_content(topic, args.type)
        else:
            print(f"Topic not found: {args.topic_id}")
